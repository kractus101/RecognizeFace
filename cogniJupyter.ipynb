{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import io\n",
    "import os\n",
    "import sys  \n",
    "import time\n",
    "import uuid\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "from io import BytesIO\n",
    "# To install this module, run:\n",
    "# python -m pip install Pillow\n",
    "from PIL import Image, ImageDraw\n",
    "from azure.cognitiveservices.vision.face import FaceClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "from azure.cognitiveservices.vision.face.models import TrainingStatusType, Person, QualityForRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This key will serve all examples in this document.\n",
    "KEY = os.environ['VISION_KEY']\n",
    "\n",
    "# This endpoint will be used in all examples in this quickstart.\n",
    "ENDPOINT = os.environ['VISION_ENDPOINT']\n",
    "\n",
    "# Base url for the Verify and Facelist/Large Facelist operations\n",
    "IMAGE_BASE_URL = 'https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/Face/images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person group: 038a8a5a-36bb-4642-ba50-5ed359b643c5\n"
     ]
    }
   ],
   "source": [
    "#Used in the Person Group Operations and Delete Person Group examples.\n",
    "# You can call list_person_groups to print a list of preexisting PersonGroups.\n",
    "# SOURCE_PERSON_GROUP_ID should be all lowercase and alphanumeric. For example, 'mygroupname' (dashes are OK).\n",
    "PERSON_GROUP_ID = str(uuid.uuid4()) # assign a random ID (or name it anything)\n",
    "\n",
    "# Used for the Delete Person Group example.\n",
    "TARGET_PERSON_GROUP_ID = str(uuid.uuid4()) # assign a random ID (or name it anything)\n",
    "\n",
    "# Create an authenticated FaceClient.\n",
    "face_client = FaceClient(ENDPOINT, CognitiveServicesCredentials(KEY))\n",
    "\n",
    "'''\n",
    "Create the PersonGroup\n",
    "'''\n",
    "# Create empty Person Group. Person Group ID must be lower case, alphanumeric, and/or with '-', '_'.\n",
    "print('Person group:', PERSON_GROUP_ID)\n",
    "face_client.person_group.create(person_group_id=PERSON_GROUP_ID, name=PERSON_GROUP_ID, recognition_model='recognition_04')\n",
    "\n",
    "# Define mumm\n",
    "mumm = face_client.person_group_person.create(PERSON_GROUP_ID, name=\"Mumm\")\n",
    "# Define pappa\n",
    "pappa = face_client.person_group_person.create(PERSON_GROUP_ID, name=\"Pappa\")\n",
    "# Define rudra\n",
    "rudra = face_client.person_group_person.create(PERSON_GROUP_ID, name=\"Rudra\")\n",
    "# Define Keya\n",
    "keya = face_client.person_group_person.create(PERSON_GROUP_ID, name=\"Keya\")\n",
    "# Define Arohi\n",
    "arohi = face_client.person_group_person.create(PERSON_GROUP_ID, name=\"Arohi\")\n",
    "\n",
    "persons = [mumm, pappa, rudra, keya, arohi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "mumm_images = [\"https://drive.usercontent.google.com/download?id=1w3YpEzsH_WBJ_sB1xUK_lYYDcE4yKicY\",\"https://drive.usercontent.google.com/download?id=1siFh9VcfQZ4YqDTWbZPPImXztNLDF2Oo\"]\n",
    "pappa_images = [\"https://drive.usercontent.google.com/download?id=1KvGt1jl28rANzI1ChNiBikZcQx7sbLnB\",\"https://drive.usercontent.google.com/download?id=1OncqTcXOah47hSTZntETDBl2hOo6z_YD\"]\n",
    "rudra_images = [\"https://drive.usercontent.google.com/download?id=10XvXF7_l69Ayqd4fiCFmXS523NXQ24cZ\",\"https://drive.usercontent.google.com/download?id=15LhUngeZx9m6SIpNupiKVRvlhn2Qfd_k\"]\n",
    "keya_images = [\"https://drive.usercontent.google.com/download?id=1Rcme5p4fDSzdZGrN5sf6UVX6qHRvzSmX\", \"https://drive.usercontent.google.com/download?id=10z3fvSDaIgdbm1DbiXL75m32A7dHMPFG\"]\n",
    "arohi_images = [\"https://drive.usercontent.google.com/download?id=1jMD2vCsTGHuJc8VrzyvkRvLUrf6sjoJN\", \"https://drive.usercontent.google.com/download?id=1PxhLoxi6QrEBdEjzQYKBYY1OFuasJMHz\",\"https://drive.usercontent.google.com/download?id=1ONNpT6UqQRl8UwQqbw9_BrfD40yeFov8\", \"https://drive.usercontent.google.com/download?id=1mzub9Qqg5ktTGRJRD8MxWzhC_Q2MTl2_\"]\n",
    "\n",
    "image_dict = {\n",
    "    'mumm_images': mumm_images,\n",
    "    'pappa_images': pappa_images,\n",
    "    'rudra_images': rudra_images,\n",
    "    'keya_images': keya_images,\n",
    "    'arohi_images': arohi_images\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "face dd89819a-b077-47e6-bf9e-faf3aa0b5a1f added to person c5dd319a-cd4a-44ab-9d52-1da1315cc955\n",
      "face b75de7a2-2c5a-47a2-812e-03cb90e89282 added to person c5dd319a-cd4a-44ab-9d52-1da1315cc955\n",
      "face 78c6afb4-e084-4223-88a1-5cb411b6c984 added to person dc332eca-e390-4584-9851-dee9bd07173e\n",
      "face 7ac79496-cf2f-48d9-9e57-c4b61f2114a0 added to person dc332eca-e390-4584-9851-dee9bd07173e\n",
      "face fd774a80-609e-4208-be36-c442ccc9928c added to person 3d9567ca-fa4f-496c-bbf3-7f5bd668b280\n",
      "face 6f478b57-200d-40e3-93ab-ebc1161108ce added to person 3d9567ca-fa4f-496c-bbf3-7f5bd668b280\n",
      "face 43a1eee7-5c8e-458c-a2fc-812a0930c1ab added to person 52304fae-bcc2-40ea-9162-d45f21025073\n",
      "face cbf1b181-93e8-4ca0-9df4-c862e5ab0d75 added to person 52304fae-bcc2-40ea-9162-d45f21025073\n",
      "face 62f72485-6eec-48ac-a363-e3958b001667 added to person a411fe22-e95e-4848-8f80-431f255bfaea\n",
      "face ae3207be-79c8-4a72-9623-5480aa3ac635 added to person a411fe22-e95e-4848-8f80-431f255bfaea\n",
      "face dc348c3e-4bb4-48a6-bc1d-ed988f31a0f4 added to person a411fe22-e95e-4848-8f80-431f255bfaea\n",
      "face a78ca9d7-6c75-493f-bd70-e6eb99ae1247 added to person a411fe22-e95e-4848-8f80-431f255bfaea\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for var_name, var_value in image_dict.items():\n",
    "    for imagees in var_value:\n",
    "        # Check if the image is of sufficent quality for recognition.\n",
    "        sufficientQuality = True\n",
    "        detected_faces = face_client.face.detect_with_url(url=imagees, detection_model='detection_03', recognition_model='recognition_04', return_face_attributes=['qualityForRecognition'])\n",
    "            # detected_faces = face_client.face.detect_with_url(url=imagees, detection_model='detection_03', recognition_model='recognition_04', return_face_attributes=['qualityForRecognition'])\n",
    "            \n",
    "            \n",
    "        for face in detected_faces:\n",
    "            if face.face_attributes.quality_for_recognition != QualityForRecognition.high:\n",
    "                sufficientQuality = False\n",
    "                break\n",
    "            if 'mumm' in var_name:\n",
    "                face_client.person_group_person.add_face_from_url(PERSON_GROUP_ID, mumm.person_id, imagees)\n",
    "                print(\"face {} added to person {}\".format(face.face_id,mumm.person_id))\n",
    "            elif 'pappa' in var_name:\n",
    "                face_client.person_group_person.add_face_from_url(PERSON_GROUP_ID, pappa.person_id, imagees)\n",
    "                print(\"face {} added to person {}\".format(face.face_id,pappa.person_id))\n",
    "            elif 'rudra' in var_name:\n",
    "                face_client.person_group_person.add_face_from_url(PERSON_GROUP_ID, rudra.person_id, imagees)\n",
    "                print(\"face {} added to person {}\".format(face.face_id,rudra.person_id))\n",
    "            elif 'keya' in var_name:\n",
    "                face_client.person_group_person.add_face_from_url(PERSON_GROUP_ID, keya.person_id, imagees)\n",
    "                print(\"face {} added to person {}\".format(face.face_id,keya.person_id))\n",
    "            elif 'arohi' in var_name:\n",
    "                face_client.person_group_person.add_face_from_url(PERSON_GROUP_ID, arohi.person_id, imagees)\n",
    "                print(\"face {} added to person {}\".format(face.face_id,arohi.person_id))\n",
    "\n",
    "\n",
    "        if not sufficientQuality:\n",
    "            print('here')\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pg resource is 038a8a5a-36bb-4642-ba50-5ed359b643c5\n",
      "<msrest.pipeline.ClientRawResponse object at 0x00000241FC0B98E0>\n",
      "Training status: running.\n",
      "\n",
      "Training status: succeeded.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the person group\n",
    "print(\"pg resource is {}\".format(PERSON_GROUP_ID))\n",
    "rawresponse = face_client.person_group.train(PERSON_GROUP_ID, raw= True)\n",
    "print(rawresponse)\n",
    "\n",
    "while (True):\n",
    "    training_status = face_client.person_group.get_training_status(PERSON_GROUP_ID)\n",
    "    print(\"Training status: {}.\".format(training_status.status))\n",
    "    print()\n",
    "    if (training_status.status is TrainingStatusType.succeeded):\n",
    "        break\n",
    "    elif (training_status.status is TrainingStatusType.failed):\n",
    "        face_client.person_group.delete(person_group_id=PERSON_GROUP_ID)\n",
    "        sys.exit('Training the person group has failed.')\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pausing for 10 seconds to avoid triggering rate limit on free account...\n",
      "Identifying faces in image\n",
      "No person identified for face ID 19c09890-0f62-4c07-a72b-6ad637236c15 in image.\n",
      "No person identified for face ID 7e782ff4-1493-4d48-aad8-61fec3780d7b in image.\n",
      "Person is identified for face ID 1e85a2df-ac31-40be-b4e1-fdb3fbff0b1d in image, with a confidence of 0.9455.\n",
      "verification result: True. confidence: 0.9455\n",
      "No person identified for face ID e71e4178-0761-4a31-a5cd-58ee9a0bc7a9 in image.\n",
      "No person identified for face ID e8e639aa-ca1c-4869-878c-195057e648af in image.\n",
      "No person identified for face ID 78e11f38-b431-4091-a93e-5d21c6ae0558 in image.\n",
      "No person identified for face ID 4f4998d8-1584-4395-b677-161e49587cec in image.\n",
      "\n",
      "End of quickstart.\n"
     ]
    }
   ],
   "source": [
    "# Group image for testing against\n",
    "# test_image = \"https://drive.usercontent.google.com/download?id=1ISizVhL6OgGb6x3DFC3h6K40dqT4ulj9\" #family photo\n",
    "test_image = \"https://drive.usercontent.google.com/download?id=1tlTZdMhmqWBFqp_DP_dXqMnNPEw2DiZL\"\n",
    "\n",
    "print('Pausing for 10 seconds to avoid triggering rate limit on free account...')\n",
    "time.sleep (10)\n",
    "\n",
    "# Detect faces\n",
    "face_ids = []\n",
    "# We use detection model 3 to get better performance, recognition model 4 to support quality for recognition attribute.\n",
    "faces = face_client.face.detect_with_url(test_image, detection_model='detection_03', recognition_model='recognition_04', return_face_attributes=['qualityForRecognition'])\n",
    "for face in faces:\n",
    "    # Only take the face if it is of sufficient quality.\n",
    "    if face.face_attributes.quality_for_recognition == QualityForRecognition.high or face.face_attributes.quality_for_recognition == QualityForRecognition.medium:\n",
    "        face_ids.append(face.face_id)\n",
    "\n",
    "# Identify faces\n",
    "results = face_client.face.identify(face_ids, PERSON_GROUP_ID)\n",
    "print('Identifying faces in image')\n",
    "if not results:\n",
    "    print('No person identified in the person group')\n",
    "for identifiedFace in results:\n",
    "    if len(identifiedFace.candidates) > 0:\n",
    "        print('Person is identified for face ID {} in image, with a confidence of {}.'.format(identifiedFace.face_id, identifiedFace.candidates[0].confidence)) # Get topmost confidence score\n",
    "\n",
    "        # Verify faces\n",
    "        verify_result = face_client.face.verify_face_to_person(identifiedFace.face_id, identifiedFace.candidates[0].person_id, PERSON_GROUP_ID)\n",
    "        print('verification result: {}. confidence: {}'.format(verify_result.is_identical, verify_result.confidence))\n",
    "    else:\n",
    "        print('No person identified for face ID {} in image.'.format(identifiedFace.face_id))\n",
    " \n",
    "\n",
    "print()\n",
    "print('End of quickstart.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
