{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import uuid\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "from io import BytesIO\n",
    "# To install this module, run:\n",
    "# python -m pip install Pillow\n",
    "from PIL import Image, ImageDraw\n",
    "from azure.cognitiveservices.vision.face import FaceClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "from azure.cognitiveservices.vision.face.models import TrainingStatusType, Person, QualityForRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This key will serve all examples in this document.\n",
    "KEY = os.environ['VISION_KEY']\n",
    "\n",
    "# This endpoint will be used in all examples in this quickstart.\n",
    "ENDPOINT = os.environ['VISION_ENDPOINT']\n",
    "\n",
    "# Base url for the Verify and Facelist/Large Facelist operations\n",
    "IMAGE_BASE_URL = 'https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/Face/images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person group: f958b312-f656-44e9-b004-9c610e5ba53a\n"
     ]
    }
   ],
   "source": [
    "#Used in the Person Group Operations and Delete Person Group examples.\n",
    "# You can call list_person_groups to print a list of preexisting PersonGroups.\n",
    "# SOURCE_PERSON_GROUP_ID should be all lowercase and alphanumeric. For example, 'mygroupname' (dashes are OK).\n",
    "PERSON_GROUP_ID = str(uuid.uuid4()) # assign a random ID (or name it anything)\n",
    "\n",
    "# Used for the Delete Person Group example.\n",
    "TARGET_PERSON_GROUP_ID = str(uuid.uuid4()) # assign a random ID (or name it anything)\n",
    "\n",
    "# Create an authenticated FaceClient.\n",
    "face_client = FaceClient(ENDPOINT, CognitiveServicesCredentials(KEY))\n",
    "\n",
    "'''\n",
    "Create the PersonGroup\n",
    "'''\n",
    "# Create empty Person Group. Person Group ID must be lower case, alphanumeric, and/or with '-', '_'.\n",
    "print('Person group:', PERSON_GROUP_ID)\n",
    "face_client.person_group.create(person_group_id=PERSON_GROUP_ID, name=PERSON_GROUP_ID, recognition_model='recognition_04')\n",
    "\n",
    "# Define mumm\n",
    "mum = face_client.person_group_person.create(PERSON_GROUP_ID, name=\"Mum\")\n",
    "# Define pappa\n",
    "pappa = face_client.person_group_person.create(PERSON_GROUP_ID, name=\"Pappa\")\n",
    "# Define rudra\n",
    "rudra = face_client.person_group_person.create(PERSON_GROUP_ID, name=\"Rudra\")\n",
    "# Define rudra\n",
    "keya = face_client.person_group_person.create(PERSON_GROUP_ID, name=\"Keya\")\n",
    "# Define rudra\n",
    "arohi = face_client.person_group_person.create(PERSON_GROUP_ID, name=\"Arohi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mumm_images = [\"https://drive.usercontent.google.com/download?id=1w3YpEzsH_WBJ_sB1xUK_lYYDcE4yKicY\",\"https://drive.usercontent.google.com/download?id=1siFh9VcfQZ4YqDTWbZPPImXztNLDF2Oo\"]\n",
    "pappa_images = [\"https://drive.usercontent.google.com/download?id=1KvGt1jl28rANzI1ChNiBikZcQx7sbLnB\",\"https://drive.usercontent.google.com/download?id=1OncqTcXOah47hSTZntETDBl2hOo6z_YD\"]\n",
    "rudra_images = [\"https://drive.usercontent.google.com/download?id=10XvXF7_l69Ayqd4fiCFmXS523NXQ24cZ\",\"https://drive.usercontent.google.com/download?id=15LhUngeZx9m6SIpNupiKVRvlhn2Qfd_k\"]\n",
    "keya_images = [\"https://drive.usercontent.google.com/download?id=1Rcme5p4fDSzdZGrN5sf6UVX6qHRvzSmX\", \"https://drive.usercontent.google.com/download?id=10z3fvSDaIgdbm1DbiXL75m32A7dHMPFG\"]\n",
    "arohi_images = [\"https://drive.usercontent.google.com/download?id=1jMD2vCsTGHuJc8VrzyvkRvLUrf6sjoJN\", \"https://drive.usercontent.google.com/download?id=1PxhLoxi6QrEBdEjzQYKBYY1OFuasJMHz\",\"https://drive.usercontent.google.com/download?id=1ONNpT6UqQRl8UwQqbw9_BrfD40yeFov8\", \"https://drive.usercontent.google.com/download?id=1mzub9Qqg5ktTGRJRD8MxWzhC_Q2MTl2_\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "face f4ffc50e-4740-4578-bcb3-9a5b162cc2a1 added to person 92de2c7c-c67e-43f1-b517-62b4973317b5\n",
      "face bb7c37b3-5f98-4ba1-98cb-c74484819b40 added to person 92de2c7c-c67e-43f1-b517-62b4973317b5\n",
      "here\n"
     ]
    }
   ],
   "source": [
    "for image in mumm_images:\n",
    "    # Check if the image is of sufficent quality for recognition.\n",
    "    sufficientQuality = True\n",
    "    # detected_faces = face_client.face.detect_with_url(url=image, detection_model='detection_03', recognition_model='recognition_04', return_face_attributes=['qualityForRecognition'])\n",
    "    detected_faces = face_client.face.detect_with_url(url=image, detection_model='detection_03', recognition_model='recognition_04', return_face_attributes=['qualityForRecognition'])\n",
    "    \n",
    "    for face in detected_faces:\n",
    "        if face.face_attributes.quality_for_recognition != QualityForRecognition.high:\n",
    "            sufficientQuality = False\n",
    "            break\n",
    "        face_client.person_group_person.add_face_from_url(PERSON_GROUP_ID, mum.person_id, image)\n",
    "        print(\"face {} added to person {}\".format(face.face_id, mum.person_id))\n",
    "\n",
    "    if not sufficientQuality:\n",
    "        print('here')\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "face 5bbcdaa1-7f4b-4157-a6c7-57e8f8b93958 added to person d9e3d167-e750-4842-a322-5f2903ca02b7\n",
      "face 0b2d0683-e3ab-4675-b92b-f3f1e30e58a6 added to person d9e3d167-e750-4842-a322-5f2903ca02b7\n"
     ]
    }
   ],
   "source": [
    "for image in pappa_images:\n",
    "    # Check if the image is of sufficent quality for recognition.\n",
    "    sufficientQuality = True\n",
    "    # detected_faces = face_client.face.detect_with_url(url=image, detection_model='detection_03', recognition_model='recognition_04', return_face_attributes=['qualityForRecognition'])\n",
    "    detected_faces = face_client.face.detect_with_url(url=image, detection_model='detection_03', recognition_model='recognition_04', return_face_attributes=['qualityForRecognition'])\n",
    "    \n",
    "    for face in detected_faces:\n",
    "        if face.face_attributes.quality_for_recognition != QualityForRecognition.high:\n",
    "            sufficientQuality = False\n",
    "            break\n",
    "        face_client.person_group_person.add_face_from_url(PERSON_GROUP_ID, pappa.person_id, image)\n",
    "        print(\"face {} added to person {}\".format(face.face_id, pappa.person_id))\n",
    "\n",
    "    if not sufficientQuality:\n",
    "        print('here')\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "face 4718d6b4-55a0-497c-a5ad-8ea679e8749a added to person 174b9d1b-5703-41e4-bb2a-d3a087fa0307\n",
      "face cc20dbcd-21ad-48cc-8437-4482d19f5b69 added to person 174b9d1b-5703-41e4-bb2a-d3a087fa0307\n"
     ]
    }
   ],
   "source": [
    "for image in keya_images:\n",
    "    # Check if the image is of sufficent quality for recognition.\n",
    "    sufficientQuality = True\n",
    "    # detected_faces = face_client.face.detect_with_url(url=image, detection_model='detection_03', recognition_model='recognition_04', return_face_attributes=['qualityForRecognition'])\n",
    "    detected_faces = face_client.face.detect_with_url(url=image, detection_model='detection_03', recognition_model='recognition_04', return_face_attributes=['qualityForRecognition'])\n",
    "    \n",
    "    for face in detected_faces:\n",
    "        if face.face_attributes.quality_for_recognition != QualityForRecognition.high:\n",
    "            sufficientQuality = False\n",
    "            break\n",
    "        face_client.person_group_person.add_face_from_url(PERSON_GROUP_ID, keya.person_id, image)\n",
    "        print(\"face {} added to person {}\".format(face.face_id, keya.person_id))\n",
    "\n",
    "    if not sufficientQuality:\n",
    "        print('here')\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "face 8b1fcf08-103b-495b-83f0-8f0181dcee81 added to person 39440058-8908-43e0-ac81-83cdc8fdb361\n",
      "face 5adf3fe4-4c2d-4bd4-b301-15ac1e8ed9f0 added to person 39440058-8908-43e0-ac81-83cdc8fdb361\n",
      "face 8f947841-c337-4150-9b7b-ad92c9241857 added to person 39440058-8908-43e0-ac81-83cdc8fdb361\n",
      "face 2324bebf-1ba1-4ea6-a234-e7834cf14828 added to person 39440058-8908-43e0-ac81-83cdc8fdb361\n"
     ]
    }
   ],
   "source": [
    "for image in arohi_images:\n",
    "    # Check if the image is of sufficent quality for recognition.\n",
    "    sufficientQuality = True\n",
    "    # detected_faces = face_client.face.detect_with_url(url=image, detection_model='detection_03', recognition_model='recognition_04', return_face_attributes=['qualityForRecognition'])\n",
    "    detected_faces = face_client.face.detect_with_url(url=image, detection_model='detection_03', recognition_model='recognition_04', return_face_attributes=['qualityForRecognition'])\n",
    "    \n",
    "    for face in detected_faces:\n",
    "        if face.face_attributes.quality_for_recognition != QualityForRecognition.high:\n",
    "            sufficientQuality = False\n",
    "            break\n",
    "        face_client.person_group_person.add_face_from_url(PERSON_GROUP_ID, arohi.person_id, image)\n",
    "        print(\"face {} added to person {}\".format(face.face_id, arohi.person_id))\n",
    "\n",
    "    if not sufficientQuality:\n",
    "        print('here')\n",
    "        continue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pg resource is f958b312-f656-44e9-b004-9c610e5ba53a\n",
      "<msrest.pipeline.ClientRawResponse object at 0x000001B5F0EA0250>\n",
      "Training status: succeeded.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the person group\n",
    "print(\"pg resource is {}\".format(PERSON_GROUP_ID))\n",
    "rawresponse = face_client.person_group.train(PERSON_GROUP_ID, raw= True)\n",
    "print(rawresponse)\n",
    "\n",
    "while (True):\n",
    "    training_status = face_client.person_group.get_training_status(PERSON_GROUP_ID)\n",
    "    print(\"Training status: {}.\".format(training_status.status))\n",
    "    print()\n",
    "    if (training_status.status is TrainingStatusType.succeeded):\n",
    "        break\n",
    "    elif (training_status.status is TrainingStatusType.failed):\n",
    "        face_client.person_group.delete(person_group_id=PERSON_GROUP_ID)\n",
    "        sys.exit('Training the person group has failed.')\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pausing for 10 seconds to avoid triggering rate limit on free account...\n",
      "QualityForRecognition.high\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bc66a\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\IPython\\core\\interactiveshell.py:3516: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# Group image for testing against\n",
    "# test_image = \"https://drive.usercontent.google.com/download?id=1ISizVhL6OgGb6x3DFC3h6K40dqT4ulj9\" #family photo\n",
    "test_image = \"https://drive.usercontent.google.com/download?id=1tlTZdMhmqWBFqp_DP_dXqMnNPEw2DiZL\"\n",
    "\n",
    "print('Pausing for 10 seconds to avoid triggering rate limit on free account...')\n",
    "time.sleep (10)\n",
    "\n",
    "# Detect faces\n",
    "face_ids = []\n",
    "# We use detection model 3 to get better performance, recognition model 4 to support quality for recognition attribute.\n",
    "faces = face_client.face.detect_with_url(test_image, detection_model='detection_03', recognition_model='recognition_04', return_face_attributes=['qualityForRecognition'])\n",
    "for face in faces:\n",
    "    print(face.face_attributes.quality_for_recognition)\n",
    "    sys.exit()\n",
    "    # Only take the face if it is of sufficient quality.\n",
    "    if face.face_attributes.quality_for_recognition == QualityForRecognition.high or face.face_attributes.quality_for_recognition == QualityForRecognition.medium:\n",
    "        face_ids.append(face.face_id)\n",
    "\n",
    "# Identify faces\n",
    "# results = face_client.face.identify(face_ids, PERSON_GROUP_ID)\n",
    "# print('Identifying faces in image')\n",
    "# if not results:\n",
    "#     print('No person identified in the person group')\n",
    "# for identifiedFace in results:\n",
    "#     if len(identifiedFace.candidates) > 0:\n",
    "#         print('Person is identified for face ID {} in image, with a confidence of {}.'.format(identifiedFace.face_id, identifiedFace.candidates[0].confidence)) # Get topmost confidence score\n",
    "\n",
    "#         # Verify faces\n",
    "#         verify_result = face_client.face.verify_face_to_person(identifiedFace.face_id, identifiedFace.candidates[0].person_id, PERSON_GROUP_ID)\n",
    "#         print('verification result: {}. confidence: {}'.format(verify_result.is_identical, verify_result.confidence))\n",
    "#     else:\n",
    "#         print('No person identified for face ID {} in image.'.format(identifiedFace.face_id))\n",
    " \n",
    "\n",
    "# print()\n",
    "# print('End of quickstart.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
